# File: cloud_functions/observation_details/main.py
import functions_framework
import requests
from google.cloud import bigquery
import json
import logging
from datetime import datetime
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_observation_details(base_url: str, headers: dict, site_ids: str, 
                          from_date: str, thru_date: str) -> dict:
    """Retrieve observation details from JCR API."""
    endpoint = f"{base_url}/external/api/v1.0/Observation/ObservationDetails"
    
    payload = {
        "site_id": site_ids,
        "from_date": from_date,
        "thru_date": thru_date
    }
    
    try:
        response = requests.post(endpoint, headers=headers, json=payload)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        logger.error(f"API error: {e}")
        raise

def load_to_bigquery(data: dict, project_id: str, dataset_id: str):
    """Load observation details data to BigQuery."""
    client = bigquery.Client(project=project_id)
    
    # Table mappings with their schemas
    table_configs = {
        'observation_headers': {
            'table_id': f"{project_id}.{dataset_id}.observation_headers",
            'schema': [
                bigquery.SchemaField("tracer_id", "INTEGER"),
                bigquery.SchemaField("observation_id", "INTEGER"),
                bigquery.SchemaField("observation_title", "STRING"),
                bigquery.SchemaField("contracted_service", "STRING"),
                bigquery.SchemaField("survey_team", "STRING"),
                bigquery.SchemaField("staff_interviewed", "STRING"),
                bigquery.SchemaField("observation_date", "TIMESTAMP"),
                bigquery.SchemaField("last_updated", "TIMESTAMP")
            ]
        },
        'observation_details': {
            'table_id': f"{project_id}.{dataset_id}.observation_details",
            'schema': [
                bigquery.SchemaField("observation_id", "INTEGER"),
                bigquery.SchemaField("question_id", "INTEGER"),
                bigquery.SchemaField("additional_information", "STRING"),
                bigquery.SchemaField("multiple_choices", "STRING"),
                bigquery.SchemaField("numerator", "INTEGER"),
                bigquery.SchemaField("denominator", "INTEGER"),
                bigquery.SchemaField("is_not_applicable", "BOOLEAN"),
                bigquery.SchemaField("question_response", "STRING")
            ]
        }
    }
    
    try:
        for table_name, config in table_configs.items():
            if table_name in data and data[table_name]:
                job_config = bigquery.LoadJobConfig(
                    write_disposition="WRITE_APPEND",
                    schema=config['schema']
                )
                
                job = client.load_table_from_json(
                    data[table_name],
                    config['table_id'],
                    job_config=job_config
                )
                job.result()
                logger.info(f"Loaded {len(data[table_name])} rows to {config['table_id']}")
                
    except Exception as e:
        logger.error(f"BigQuery load error: {e}")
        raise

@functions_framework.http
def handle_observation_details(request):
    """Cloud Function to handle observation details retrieval and storage."""
    try:
        # Get request data
        request_json = request.get_json(silent=True)
        if not request_json:
            raise ValueError("Missing request data")
            
        required_fields = ['auth_headers', 'site_ids', 'from_date', 'thru_date']
        for field in required_fields:
            if field not in request_json:
                raise ValueError(f"Missing required field: {field}")
        
        # Get configuration from environment variables
        project_id = os.environ.get('GCP_PROJECT')
        dataset_id = os.environ.get('BIGQUERY_DATASET')
        base_url = os.environ.get('JCR_BASE_URL')
        
        # Get observation details
        details_data = get_observation_details(
            base_url,
            request_json['auth_headers'],
            request_json['site_ids'],
            request_json['from_date'],
            request_json['thru_date']
        )
        
        # Load to BigQuery
        load_to_bigquery(details_data, project_id, dataset_id)
        
        return json.dumps({"success": True}), 200, {
            'Content-Type': 'application/json'
        }
        
    except Exception as e:
        error_message = f"Observation details processing failed: {str(e)}"
        logger.error(error_message)
        return json.dumps({
            "success": False,
            "error": error_message
        }), 500, {'Content-Type': 'application/json'}